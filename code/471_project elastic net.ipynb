{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import hstack\n",
    "from sklearn import metrics\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./student-mat.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 33)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = shuffle(range(395), random_state=2019425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "395/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[indexes[:79], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"./test_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_indexes = indexes[79:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(other_indexes) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_1 = other_indexes[:63]\n",
    "cv_2 = other_indexes[63:63*2]\n",
    "cv_3 = other_indexes[63*2:63*3]\n",
    "cv_4 = other_indexes[63*3:63*4]\n",
    "cv_5 = other_indexes[63*4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.iloc[cv_1, :]\n",
    "df_2 = df.iloc[cv_2, :]\n",
    "df_3 = df.iloc[cv_3, :]\n",
    "df_4 = df.iloc[cv_4, :]\n",
    "df_5 = df.iloc[cv_5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"./cv_1.csv\", index=False)\n",
    "df_2.to_csv(\"./cv_2.csv\", index=False)\n",
    "df_3.to_csv(\"./cv_3.csv\", index=False)\n",
    "df_4.to_csv(\"./cv_4.csv\", index=False)\n",
    "df_5.to_csv(\"./cv_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>teacher</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>R</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>at_home</td>\n",
       "      <td>at_home</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>services</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "178     GP   M   16       R     GT3       T     4     2   teacher  services   \n",
       "35      GP   F   15       U     GT3       T     2     3     other     other   \n",
       "136     GP   M   17       R     GT3       T     3     4   at_home     other   \n",
       "273     GP   M   17       R     GT3       T     1     2   at_home   at_home   \n",
       "31      GP   M   15       U     GT3       T     4     4  services  services   \n",
       "\n",
       "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "178  ...      4        3      3     3     4      3       10  10   8   9  \n",
       "35   ...      3        5      1     1     1      5        0   8   7   6  \n",
       "136  ...      5        4      5     2     4      5        0  10   0   0  \n",
       "273  ...      3        5      2     2     2      1        2  15  14  14  \n",
       "31   ...      4        3      1     1     1      5        0  17  16  17  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G3', 'age'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([df_1, df_2, df_3, df_4])\n",
    "train_y = train_df['G3'].values\n",
    "train_age = train_df['age'].values.reshape(-1,1)\n",
    "train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G3', 'age'], axis=1)\n",
    "\n",
    "train_x = train_df_dropped.values\n",
    "train_x = enc.transform(train_x).toarray()\n",
    "train_x = np.hstack((train_x, train_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "vali_df = df_5\n",
    "vali_y = vali_df['G3'].values\n",
    "vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G3', 'age'], axis=1)\n",
    "\n",
    "vali_x = vali_df_dropped.values\n",
    "vali_x = enc.transform(vali_x).toarray()\n",
    "vali_x = np.hstack((vali_x, vali_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(alpha=0.0001,\n",
    "                   l1_ratio=0.5,\n",
    "                   fit_intercept=True,\n",
    "                   normalize=False,\n",
    "                   max_iter=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.0001, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.22110492,  9.81054282,  6.24177337, 10.86259956,  7.41785403,\n",
       "        2.95522143,  4.00034319,  1.7683242 ,  9.88424141,  1.68458363,\n",
       "        9.36314234, 11.47442383, 11.87496734,  9.38796563,  4.40629454,\n",
       "        8.60780055, 11.29986719,  6.3779329 ,  7.83398395,  8.55770356,\n",
       "       13.75772127, 17.18309051, 15.27944306, 11.20389637,  8.36358143,\n",
       "       12.49709544, 15.74385738, 15.38951099,  9.39458522, 19.48920212,\n",
       "       15.65057032, 17.2457531 ,  7.25061365,  8.23857145, 11.71813551,\n",
       "       16.77352179, 13.56904588,  9.69327651,  6.14495702, 14.45839539,\n",
       "       16.4837604 ,  7.97059553,  9.80078867, 13.77118199, 12.17071586,\n",
       "       16.28786841,  7.99371857,  9.65123163, 10.62324109,  9.2066112 ,\n",
       "        1.45361915, 22.31517268, 10.51332729,  5.25718884,  7.09831589,\n",
       "       16.77967787,  9.40148589, 13.2870069 , 12.95590306,  5.32648298,\n",
       "       13.08454616,  4.37068906,  9.43302179,  8.02412121])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vali_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7967092734169612"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(vali_y, model.predict(vali_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.50495115,  -3.62269254,  -7.22074182,   0.33206069,\n",
       "        -4.30856569,  -6.18751209,  -5.31187799, -11.06254263,\n",
       "         0.81699557, -10.8592637 ,  -4.9978621 ,   0.09900007,\n",
       "         7.92374535,   3.12904313,  -2.77095466,   0.73896963,\n",
       "         1.59241186,   0.97085375,  -1.41745857,  -1.48418929,\n",
       "         4.25853104,  -0.29046539,   1.78598716,   5.09983871,\n",
       "        -5.01398082,   2.13439982,   2.74227264,  -3.45303783,\n",
       "         8.12504586,   2.15096553,   1.01309351,   3.62929165,\n",
       "       -12.01109608,  -5.76093819,   2.18607845,   3.75330656,\n",
       "        -2.35045977,   0.66096781,   1.08773496,   1.78614447,\n",
       "         2.34126652,  -1.83117569,  -1.15093038,  -2.73985006,\n",
       "        -1.67674071,   0.77623743,  -1.61224662,   2.08633606,\n",
       "         1.2232216 ,  -9.28191647,  -4.74202887,   3.74962122,\n",
       "        -1.61825116,  -2.19250961,   4.65056703,   1.73294951,\n",
       "         0.59187049,   1.61837623,  -0.3715606 ,   4.66644934,\n",
       "         5.06523211, -10.68127746,  -2.67182892,  -2.35775792])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vali_y - model.predict(vali_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./student-mat.csv', sep=';')\n",
    "\n",
    "df_1 = pd.read_csv(\"./cv_1.csv\")\n",
    "df_2 = pd.read_csv(\"./cv_2.csv\")\n",
    "df_3 = pd.read_csv(\"./cv_3.csv\")\n",
    "df_4 = pd.read_csv(\"./cv_4.csv\")\n",
    "df_5 = pd.read_csv(\"./cv_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dict = {\n",
    "    1: {\n",
    "        'train': [df_1, df_2, df_3, df_4],\n",
    "        'vali': df_5\n",
    "    },\n",
    "    2: {\n",
    "        'train': [df_1, df_2, df_3, df_5],\n",
    "        'vali': df_4\n",
    "    },\n",
    "    3: {\n",
    "        'train': [df_1, df_2, df_5, df_4],\n",
    "        'vali': df_3\n",
    "    },\n",
    "    4: {\n",
    "        'train': [df_1, df_5, df_3, df_4],\n",
    "        'vali': df_2\n",
    "    },\n",
    "    5: {\n",
    "        'train': [df_5, df_2, df_3, df_4],\n",
    "        'vali': df_1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in cv_dict:\n",
    "    # Training set\n",
    "    train_df = pd.concat(cv_dict[cv]['train'])\n",
    "    train_y = train_df['G3'].values\n",
    "    train_age = train_df['age'].values.reshape(-1,1)\n",
    "    train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "    train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "    train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "    train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "    train_x = train_df_dropped.values\n",
    "    train_x = enc.transform(train_x).toarray()\n",
    "    train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "    np.savez('./cv_npz/cv_{}_train.npz'.format(cv), train_x=train_x, train_y=train_y)\n",
    "\n",
    "    # Validation set\n",
    "    vali_df = cv_dict[cv]['vali']\n",
    "    vali_y = vali_df['G3'].values\n",
    "    vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "    vali_g1 = vali_df['G1'].values.reshape(-1,1)\n",
    "    vali_g2 = vali_df['G2'].values.reshape(-1,1)\n",
    "    vali_abs = vali_df['absences'].values.reshape(-1,1)\n",
    "    vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "    vali_x = vali_df_dropped.values\n",
    "    vali_x = enc.transform(vali_x).toarray()\n",
    "    vali_x = np.hstack((vali_x, vali_age, vali_abs, vali_g1, vali_g2))\n",
    "    np.savez('./cv_npz/cv_{}_vali.npz'.format(cv), vali_x=vali_x, vali_y=vali_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1000, 0.1): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.2): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.3): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.4): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.5): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.6): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.7): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.8): [21.37455452727478, -0.05116282882839753],\n",
       " (1000, 0.9): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.1): [19.546031366636306, 0.04259275723928502],\n",
       " (100, 0.2): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.3): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.4): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.5): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.6): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.7): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.8): [21.37455452727478, -0.05116282882839753],\n",
       " (100, 0.9): [21.37455452727478, -0.05116282882839753],\n",
       " (10, 0.1): [6.2813765355214155, 0.7073547819418332],\n",
       " (10, 0.2): [6.673465381220835, 0.6888788074197162],\n",
       " (10, 0.3): [7.0772349689954925, 0.6694928540429015],\n",
       " (10, 0.4): [7.556851063362778, 0.6460427285974515],\n",
       " (10, 0.5): [8.117618280249312, 0.6184593976873185],\n",
       " (10, 0.6): [8.775316345854023, 0.5858994276588113],\n",
       " (10, 0.7): [9.457137043720303, 0.5516882097213089],\n",
       " (10, 0.8): [10.028453714873274, 0.5234519928454617],\n",
       " (10, 0.9): [10.708937046206147, 0.48980558701460913],\n",
       " (1, 0.1): [4.047631121428523, 0.8130134908486755],\n",
       " (1, 0.2): [4.057490464116118, 0.8128057815217105],\n",
       " (1, 0.3): [4.060705221751189, 0.8128967523110877],\n",
       " (1, 0.4): [4.060403495022063, 0.8131820135336676],\n",
       " (1, 0.5): [4.059283175957864, 0.8135283112410324],\n",
       " (1, 0.6): [4.060045265986858, 0.8137900373785488],\n",
       " (1, 0.7): [4.063286515891481, 0.8139351738058955],\n",
       " (1, 0.8): [4.069700159649055, 0.8139290919950548],\n",
       " (1, 0.9): [4.080100270898962, 0.8137307581773356],\n",
       " (0.1, 0.1): [4.10965683514034, 0.8079011437690303],\n",
       " (0.1, 0.2): [4.075219424187867, 0.8101452566022378],\n",
       " (0.1, 0.3): [4.042460513366542, 0.8120598052534156],\n",
       " (0.1, 0.4): [4.007258867218477, 0.8140532195813929],\n",
       " (0.1, 0.5): [3.988536551504299, 0.8151627801587444],\n",
       " (0.1, 0.6): [3.984421616774571, 0.8155360077774931],\n",
       " (0.1, 0.7): [3.986027998904482, 0.8156996309594751],\n",
       " (0.1, 0.8): [3.9957872713989118, 0.8154620037918541],\n",
       " (0.1, 0.9): [4.001435894583318, 0.8152321788904546],\n",
       " (0.01, 0.1): [4.8453997481546525, 0.7663025305552917],\n",
       " (0.01, 0.2): [4.815140984605901, 0.7678663807302251],\n",
       " (0.01, 0.3): [4.786071826011456, 0.7693952443480653],\n",
       " (0.01, 0.4): [4.757233728921017, 0.7709472505329773],\n",
       " (0.01, 0.5): [4.731730392165503, 0.7723217978108637],\n",
       " (0.01, 0.6): [4.707388819894529, 0.7736034551013266],\n",
       " (0.01, 0.7): [4.681736130676894, 0.7749783583631111],\n",
       " (0.01, 0.8): [4.657271264649813, 0.7762909976444649],\n",
       " (0.01, 0.9): [4.632891664132092, 0.7775826069037541],\n",
       " (0.001, 0.1): [5.19089987385783, 0.7474604926076892],\n",
       " (0.001, 0.2): [5.186412074703908, 0.7476841647578267],\n",
       " (0.001, 0.3): [5.182584051868352, 0.7478726128996726],\n",
       " (0.001, 0.4): [5.178945612741178, 0.748051083833807],\n",
       " (0.001, 0.5): [5.175795429066925, 0.7482068149036064],\n",
       " (0.001, 0.6): [5.173064368552898, 0.7483385259057926],\n",
       " (0.001, 0.7): [5.170850488897782, 0.748434802440566],\n",
       " (0.001, 0.8): [5.168476552937321, 0.7485402025259982],\n",
       " (0.001, 0.9): [5.166196113760659, 0.7486425615782647],\n",
       " (0.0001, 0.1): [5.244358999932474, 0.7445847774282099],\n",
       " (0.0001, 0.2): [5.243952778412366, 0.7446054831596716],\n",
       " (0.0001, 0.3): [5.24359659032506, 0.7446233442713842],\n",
       " (0.0001, 0.4): [5.243320333862995, 0.7446371246802265],\n",
       " (0.0001, 0.5): [5.243113701787285, 0.7446476902106081],\n",
       " (0.0001, 0.6): [5.24298217954023, 0.74465462282521],\n",
       " (0.0001, 0.7): [5.2430310677234, 0.744651950898989],\n",
       " (0.0001, 0.8): [5.24324346913045, 0.7446435889676293],\n",
       " (0.0001, 0.9): [5.243434375994283, 0.7446359835545446]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "\n",
    "alphas = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "blends = [i/10 for i in range(1, 10)]\n",
    "keys = [(i, j) for i in alphas for j in blends]\n",
    "en_results = dict(zip(keys, [[0, 0,] for i in keys]))\n",
    "\n",
    "for alpha, blend in en_results:\n",
    "    cur_mse = []\n",
    "    cur_r2 = []\n",
    "    \n",
    "    for cv in cv_dict:\n",
    "        # Training set\n",
    "        train_df = pd.concat(cv_dict[cv]['train'])\n",
    "        train_y = train_df['G3'].values\n",
    "        train_age = train_df['age'].values.reshape(-1,1)\n",
    "        train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "        train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "        train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "        train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        train_x = train_df_dropped.values\n",
    "        train_x = enc.transform(train_x).toarray()\n",
    "        train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "        # Validation set\n",
    "        vali_df = cv_dict[cv]['vali']\n",
    "        vali_y = vali_df['G3'].values\n",
    "        vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "        vali_g1 = vali_df['G1'].values.reshape(-1,1)\n",
    "        vali_g2 = vali_df['G2'].values.reshape(-1,1)\n",
    "        vali_abs = vali_df['absences'].values.reshape(-1,1)\n",
    "        vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        vali_x = vali_df_dropped.values\n",
    "        vali_x = enc.transform(vali_x).toarray()\n",
    "        vali_x = np.hstack((vali_x, vali_age, vali_abs, vali_g1, vali_g2))\n",
    "\n",
    "        # Train the model\n",
    "        model = ElasticNet(alpha=alpha,\n",
    "                       l1_ratio=blend,\n",
    "                       fit_intercept=True,\n",
    "                       normalize=False,\n",
    "                       max_iter=1000000)\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # Test on the validation set\n",
    "        vali_predict = model.predict(vali_x)\n",
    "\n",
    "        # Track performance\n",
    "        cur_mse.append(metrics.mean_squared_error(vali_y, vali_predict))\n",
    "        cur_r2.append(metrics.r2_score(vali_y, vali_predict))\n",
    "        \n",
    "    en_results[(alpha, blend)] = [np.mean(cur_mse), np.mean(cur_r2)]\n",
    "    \n",
    "en_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: [21.37455452727478, -0.05116282882839753],\n",
       " 100: [21.37455452727478, -0.05116282882839753],\n",
       " 10: [11.533374623015773, 0.4490276107684511],\n",
       " 1: [4.09560842243497, 0.8132837057566938],\n",
       " 0.1: [3.998478043934745, 0.8153912770967733],\n",
       " 0.01: [4.61010027696618, 0.7787058345711817],\n",
       " 0.001: [5.164607930655503, 0.7487194171398851]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "lasso_results = dict(zip([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001], [[0, 0] for _ in range(7)]))\n",
    "\n",
    "for alpha in en_results:\n",
    "    cur_mse = []\n",
    "    cur_r2 = []\n",
    "    \n",
    "    for cv in cv_dict:\n",
    "        # Training set\n",
    "        train_df = pd.concat(cv_dict[cv]['train'])\n",
    "        train_y = train_df['G3'].values\n",
    "        train_age = train_df['age'].values.reshape(-1,1)\n",
    "        train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "        train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "        train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "        train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        train_x = train_df_dropped.values\n",
    "        train_x = enc.transform(train_x).toarray()\n",
    "        train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "        # Validation set\n",
    "        vali_df = cv_dict[cv]['vali']\n",
    "        vali_y = vali_df['G3'].values\n",
    "        vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "        vali_g1 = vali_df['G1'].values.reshape(-1,1)\n",
    "        vali_g2 = vali_df['G2'].values.reshape(-1,1)\n",
    "        vali_abs = vali_df['absences'].values.reshape(-1,1)\n",
    "        vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        vali_x = vali_df_dropped.values\n",
    "        vali_x = enc.transform(vali_x).toarray()\n",
    "        vali_x = np.hstack((vali_x, vali_age, vali_abs, vali_g1, vali_g2))\n",
    "\n",
    "        # Train the model\n",
    "        model = Lasso(alpha=alpha,\n",
    "                       fit_intercept=True,\n",
    "                       normalize=False,\n",
    "                       max_iter=1000000)\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # Test on the validation set\n",
    "        vali_predict = model.predict(vali_x)\n",
    "\n",
    "        # Track performance\n",
    "        cur_mse.append(metrics.mean_squared_error(vali_y, vali_predict))\n",
    "        cur_r2.append(metrics.r2_score(vali_y, vali_predict))\n",
    "        \n",
    "    lasso_results[alpha] = [np.mean(cur_mse), np.mean(cur_r2)]\n",
    "    \n",
    "lasso_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1000: [4.536146433241242, 0.7900682962275586],\n",
       " 100: [3.958281058688877, 0.8165398991364698],\n",
       " 10: [4.45327771043412, 0.7883942624486295],\n",
       " 1: [5.064399274295008, 0.7543514625844503],\n",
       " 0.1: [5.227506558402414, 0.7454936053710959],\n",
       " 0.01: [5.248344000188128, 0.7443709184222074],\n",
       " 0.001: [5.25050204198714, 0.7442547695099357]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "ridge_results = dict(zip([1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001], [[0, 0] for _ in range(7)]))\n",
    "\n",
    "for alpha in en_results:\n",
    "    cur_mse = []\n",
    "    cur_r2 = []\n",
    "    \n",
    "    for cv in cv_dict:\n",
    "        # Training set\n",
    "        train_df = pd.concat(cv_dict[cv]['train'])\n",
    "        train_y = train_df['G3'].values\n",
    "        train_age = train_df['age'].values.reshape(-1,1)\n",
    "        train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "        train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "        train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "        train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        train_x = train_df_dropped.values\n",
    "        train_x = enc.transform(train_x).toarray()\n",
    "        train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "        # Validation set\n",
    "        vali_df = cv_dict[cv]['vali']\n",
    "        vali_y = vali_df['G3'].values\n",
    "        vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "        vali_g1 = vali_df['G1'].values.reshape(-1,1)\n",
    "        vali_g2 = vali_df['G2'].values.reshape(-1,1)\n",
    "        vali_abs = vali_df['absences'].values.reshape(-1,1)\n",
    "        vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        vali_x = vali_df_dropped.values\n",
    "        vali_x = enc.transform(vali_x).toarray()\n",
    "        vali_x = np.hstack((vali_x, vali_age, vali_abs, vali_g1, vali_g2))\n",
    "\n",
    "        # Train the model\n",
    "        model = Ridge(alpha=alpha,\n",
    "                       fit_intercept=True,\n",
    "                       normalize=False,\n",
    "                       max_iter=1000000)\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        # Test on the validation set\n",
    "        vali_predict = model.predict(vali_x)\n",
    "\n",
    "        # Track performance\n",
    "        cur_mse.append(metrics.mean_squared_error(vali_y, vali_predict))\n",
    "        cur_r2.append(metrics.r2_score(vali_y, vali_predict))\n",
    "        \n",
    "    ridge_results[alpha] = [np.mean(cur_mse), np.mean(cur_r2)]\n",
    "    \n",
    "ridge_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "# Training set\n",
    "train_df = pd.concat([df_1, df_2, df_3, df_4, df_5])\n",
    "train_y = train_df['G3'].values\n",
    "train_age = train_df['age'].values.reshape(-1,1)\n",
    "train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "train_x = train_df_dropped.values\n",
    "train_x = enc.transform(train_x).toarray()\n",
    "train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "# Test set\n",
    "test_df = pd.read_csv('./test_set.csv')\n",
    "test_y = test_df['G3'].values\n",
    "test_age = test_df['age'].values.reshape(-1,1)\n",
    "test_g1 = test_df['G1'].values.reshape(-1,1)\n",
    "test_g2 = test_df['G2'].values.reshape(-1,1)\n",
    "test_abs = test_df['absences'].values.reshape(-1,1)\n",
    "test_df_dropped = test_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "test_x = test_df_dropped.values\n",
    "test_x = enc.transform(test_x).toarray()\n",
    "test_x = np.hstack((test_x, test_age, test_abs, test_g1, test_g2))\n",
    "\n",
    "np.savez('./cv_npz/test_train.npz'.format(cv), train_x=train_x, train_y=train_y)\n",
    "np.savez('./cv_npz/test_test.npz'.format(cv), test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = {'lasso': [], 'ridge': [], 'en': [], 'no_reg': []}\n",
    "best_params = {'lasso': 0.1, 'ridge': 100, 'en': [0.1, 0.7]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(alpha=best_params['en'][0],\n",
    "               l1_ratio=best_params['en'][1],\n",
    "               fit_intercept=True,\n",
    "               normalize=False,\n",
    "               max_iter=1000000)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Test on the validation set\n",
    "test_predict = model.predict(test_x)\n",
    "\n",
    "# Track performance\n",
    "test_result['en'] = [metrics.mean_squared_error(test_y, test_predict),\n",
    "                     metrics.r2_score(test_y, test_predict)]\n",
    "\n",
    "model = Lasso(alpha=best_params['lasso'],\n",
    "               fit_intercept=True,\n",
    "               normalize=False,\n",
    "               max_iter=1000000)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "# Test on the validation set\n",
    "test_predict = model.predict(test_x)\n",
    "\n",
    "# Track performance\n",
    "test_result['lasso'] = [metrics.mean_squared_error(test_y, test_predict),\n",
    "                        metrics.r2_score(test_y, test_predict)]\n",
    "\n",
    "model = Ridge(alpha=best_params['ridge'],\n",
    "               fit_intercept=True,\n",
    "               normalize=False,\n",
    "               max_iter=1000000)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# Test on the validation set\n",
    "test_predict = model.predict(test_x)\n",
    "\n",
    "# Track performance\n",
    "test_result['ridge'] = [metrics.mean_squared_error(test_y, test_predict),\n",
    "                        metrics.r2_score(test_y, test_predict)]\n",
    "\n",
    "model = LinearRegression(fit_intercept=True, normalize=False)\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# Test on the validation set\n",
    "test_predict = model.predict(test_x)\n",
    "\n",
    "# Track performance\n",
    "test_result['no_reg'] = [metrics.mean_squared_error(test_y, test_predict),\n",
    "                         metrics.r2_score(test_y, test_predict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': [2.8231742775443682, 0.8614040127575797],\n",
       " 'ridge': [2.8536100412196164, 0.8599098525324742],\n",
       " 'en': [2.7708078834745207, 0.8639747970489233],\n",
       " 'no_reg': [3.480643846476052, 0.829127350026296]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed Form Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{\\beta}=(X^{T}X)^{-1}X^{T}y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_1 = np.linalg.inv(np.matmul(train_x.transpose(), train_x))\n",
    "l_2 = train_x.transpose()\n",
    "l_3 = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = np.matmul(np.matmul(l_1, l_2), l_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "# Training set\n",
    "train_df = pd.concat([df_1, df_2, df_3, df_4, df_5])\n",
    "train_y = train_df['G3'].values\n",
    "train_age = train_df['age'].values.reshape(-1,1)\n",
    "train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "train_x = train_df_dropped.values\n",
    "train_x = enc.transform(train_x).toarray()\n",
    "train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "# Test set\n",
    "test_df = pd.read_csv('./test_set.csv')\n",
    "test_y = test_df['G3'].values\n",
    "test_age = test_df['age'].values.reshape(-1,1)\n",
    "test_g1 = test_df['G1'].values.reshape(-1,1)\n",
    "test_g2 = test_df['G2'].values.reshape(-1,1)\n",
    "test_abs = test_df['absences'].values.reshape(-1,1)\n",
    "test_df_dropped = test_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "test_x = test_df_dropped.values\n",
    "test_x = enc.transform(test_x).toarray()\n",
    "test_x = np.hstack((test_x, test_age, test_abs, test_g1, test_g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en_train(x, y, alpha=0.5, lamb=0.1, max_iter=1000, epsilon=1e-6):\n",
    "    \n",
    "    coef_track = []\n",
    "    \n",
    "    # Add a column for intercept coef\n",
    "    train_x = np.column_stack((np.ones(len(x)), x))\n",
    "\n",
    "    # Just initialize all coefs to 0\n",
    "    weights = np.zeros(train_x.shape[1])\n",
    "    \n",
    "    # Compute c_1, c_2 (it is same for every j)\n",
    "    c_1 = 2 * lamb * (1 - alpha)\n",
    "    c_2 = lamb * alpha\n",
    "\n",
    "    # No converge stopping\n",
    "    for iter in range(max_iter):\n",
    "        old_weights = weights.copy()\n",
    "\n",
    "        # Iterate through all coefficients\n",
    "        for j in range(len(weights)):\n",
    "            \n",
    "            # Exclude the contribution of current coefficient\n",
    "            cur_weights = weights.copy()\n",
    "            cur_weights[j] = 0\n",
    "            \n",
    "            # Compute p_j (1): residuals (without contribution of w_j)\n",
    "            predict = np.dot(train_x, cur_weights)\n",
    "            residual = y - predict\n",
    "            \n",
    "            # Compute p_j (2): weight residuals by x_j and take sum (dot product)\n",
    "            p_j = np.dot(train_x[:, j], residual)\n",
    "            \n",
    "            # Compute z_j\n",
    "            z_j = np.sum(train_x[:, j] ** 2)\n",
    "            \n",
    "            # Compare p_j with alpha * lambda and update weights\n",
    "            if p_j < -c_2:\n",
    "                weights[j] = (p_j + c_2) / (z_j + c_1)\n",
    "            elif p_j > c_2:\n",
    "                weights[j] = (p_j - c_2) / (z_j + c_1)\n",
    "            else:\n",
    "                weights[j] = 0\n",
    "                \n",
    "        # Need to specially handle the intercept (best intercept)\n",
    "        best_intercepts = y - np.dot(train_x[:, 1:], weights[1:])\n",
    "        weights[0] = np.sum(best_intercepts) / (train_x.shape[0])\n",
    "        \n",
    "        coef_track.append(weights.tolist())\n",
    "        \n",
    "        # If the update is too small, we stop the iteration\n",
    "        max_update = np.max(np.abs(weights - old_weights))\n",
    "        if max_update < epsilon:\n",
    "            # print(\"Early stop: at iteration {}\".format(iter))\n",
    "            return (weights, coef_track)\n",
    "    \n",
    "    return (weights, coef_track)\n",
    "\n",
    "\n",
    "def en_predict(x, coef):\n",
    "    x_padding = np.column_stack((np.ones(len(x)), x))\n",
    "    y_predict = np.dot(x_padding, coefs)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = en_train(train_x, train_y, alpha=0.7, lamb=0.1, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.4641526432063547, 0.8299369403573496]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test_x, test_y, coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 637.6046061515808 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{(1000, 0.1): [5.1898305502762145, 0.7586019007947982],\n",
       " (1000, 0.2): [5.105914220510753, 0.7627299959476231],\n",
       " (1000, 0.3): [5.024102872294314, 0.7667646828035627],\n",
       " (1000, 0.4): [4.953429297465515, 0.7703185616662538],\n",
       " (1000, 0.5): [4.891185673341892, 0.7736051249593453],\n",
       " (1000, 0.6): [4.833446267945211, 0.7768344963341587],\n",
       " (1000, 0.7): [4.758433210623304, 0.7808786522764268],\n",
       " (1000, 0.8): [4.661771911494286, 0.7860082579032402],\n",
       " (1000, 0.9): [4.544985472281258, 0.7921566499035165],\n",
       " (100, 0.1): [3.9528397950774647, 0.8171214292971956],\n",
       " (100, 0.2): [3.9699583282328192, 0.8165608684261318],\n",
       " (100, 0.3): [3.974569171571474, 0.8164010100154775],\n",
       " (100, 0.4): [3.966127889009273, 0.8169503125629249],\n",
       " (100, 0.5): [3.962602742983728, 0.8172942595863845],\n",
       " (100, 0.6): [3.9600923731631115, 0.8175944395849587],\n",
       " (100, 0.7): [3.9588479866542103, 0.8178387593855666],\n",
       " (100, 0.8): [3.9591899737606733, 0.8180117249493281],\n",
       " (100, 0.9): [3.961523924044492, 0.8180936127991492],\n",
       " (10, 0.1): [4.187036719536112, 0.8029062537493712],\n",
       " (10, 0.2): [4.162406798856668, 0.8042304432336899],\n",
       " (10, 0.3): [4.142419084877352, 0.8053943158269143],\n",
       " (10, 0.4): [4.127119385436208, 0.8063391192919405],\n",
       " (10, 0.5): [4.116787234898403, 0.8069973930965852],\n",
       " (10, 0.6): [4.10766136868377, 0.8075752475415591],\n",
       " (10, 0.7): [4.098832488170926, 0.8080061575103656],\n",
       " (10, 0.8): [4.0908984572049665, 0.808388965690819],\n",
       " (10, 0.9): [4.08438228921136, 0.8087430231454846],\n",
       " (1, 0.1): [4.934755363102502, 0.7613936073055424],\n",
       " (1, 0.2): [4.932293862450985, 0.7614670021362527],\n",
       " (1, 0.3): [4.930381604403896, 0.7615136775090818],\n",
       " (1, 0.4): [4.928247329835087, 0.7615771890539096],\n",
       " (1, 0.5): [4.926847779857826, 0.7616018199002312],\n",
       " (1, 0.6): [4.925833136920073, 0.761627281719931],\n",
       " (1, 0.7): [4.927515950951105, 0.7615046942682889],\n",
       " (1, 0.8): [4.931407259923052, 0.7612571354279428],\n",
       " (1, 0.9): [4.936267639574808, 0.7609605105356304],\n",
       " (0.1, 0.1): [5.2038795631117365, 0.7467211931686938],\n",
       " (0.1, 0.2): [5.204214719503346, 0.7466944155183673],\n",
       " (0.1, 0.3): [5.20454715457804, 0.7466666555443323],\n",
       " (0.1, 0.4): [5.2049597601145035, 0.7466335100745132],\n",
       " (0.1, 0.5): [5.206152207738205, 0.7465639403730149],\n",
       " (0.1, 0.6): [5.207188126442658, 0.7464998127629867],\n",
       " (0.1, 0.7): [5.20819317702532, 0.7464389926636711],\n",
       " (0.1, 0.8): [5.209798111548326, 0.7463412683779687],\n",
       " (0.1, 0.9): [5.212353482509361, 0.7461922293045344],\n",
       " (0.01, 0.1): [5.243518269998286, 0.7445728279225592],\n",
       " (0.01, 0.2): [5.243686194037559, 0.7445628031770534],\n",
       " (0.01, 0.3): [5.243858844440532, 0.7445525238078303],\n",
       " (0.01, 0.4): [5.244035330568763, 0.7445420303797565],\n",
       " (0.01, 0.5): [5.244203841067309, 0.7445317293376287],\n",
       " (0.01, 0.6): [5.244400282234123, 0.7445200911915979],\n",
       " (0.01, 0.7): [5.24464085162388, 0.7445061842725897],\n",
       " (0.01, 0.8): [5.244860967047564, 0.7444931008419498],\n",
       " (0.01, 0.9): [5.245094120774313, 0.7444795664940941],\n",
       " (0.001, 0.1): [5.248156927962426, 0.7443181471170333],\n",
       " (0.001, 0.2): [5.2481778040485585, 0.744316898056437],\n",
       " (0.001, 0.3): [5.248198801409101, 0.7443156412188656],\n",
       " (0.001, 0.4): [5.248219850450941, 0.744314381825719],\n",
       " (0.001, 0.5): [5.248239706379815, 0.7443132131286422],\n",
       " (0.001, 0.6): [5.248261384535796, 0.7443119323395584],\n",
       " (0.001, 0.7): [5.24828275520021, 0.7443106630979089],\n",
       " (0.001, 0.8): [5.248304218519787, 0.7443093884749761],\n",
       " (0.001, 0.9): [5.248325768162852, 0.7443081087733915],\n",
       " (0.0001, 0.1): [5.248645430653122, 0.7442912327059362],\n",
       " (0.0001, 0.2): [5.248647587139596, 0.7442911037942533],\n",
       " (0.0001, 0.3): [5.248649744466851, 0.7442909748312679],\n",
       " (0.0001, 0.4): [5.248651902570383, 0.7442908458224463],\n",
       " (0.0001, 0.5): [5.248654061539794, 0.7442907167602778],\n",
       " (0.0001, 0.6): [5.248656221361172, 0.7442905876461509],\n",
       " (0.0001, 0.7): [5.248658382624148, 0.7442904584613627],\n",
       " (0.0001, 0.8): [5.248660544227518, 0.7442903292409347],\n",
       " (0.0001, 0.9): [5.248662706566691, 0.74429019997721]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "alphas = [1000, 100, 10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
    "blends = [i/10 for i in range(1, 10)]\n",
    "keys = [(i, j) for i in alphas for j in blends]\n",
    "en_results = dict(zip(keys, [[0, 0,] for i in keys]))\n",
    "count = 0\n",
    "\n",
    "for alpha, blend in en_results:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    \n",
    "    cur_mse = []\n",
    "    cur_r2 = []\n",
    "    cur_ar2 = []\n",
    "    \n",
    "    for cv in cv_dict:\n",
    "        # Training set\n",
    "        train_df = pd.concat(cv_dict[cv]['train'])\n",
    "        train_y = train_df['G3'].values\n",
    "        train_age = train_df['age'].values.reshape(-1,1)\n",
    "        train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "        train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "        train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "        train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        train_x = train_df_dropped.values\n",
    "        train_x = enc.transform(train_x).toarray()\n",
    "        train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "        # Validation set\n",
    "        vali_df = cv_dict[cv]['vali']\n",
    "        vali_y = vali_df['G3'].values\n",
    "        vali_age = vali_df['age'].values.reshape(-1,1)\n",
    "        vali_g1 = vali_df['G1'].values.reshape(-1,1)\n",
    "        vali_g2 = vali_df['G2'].values.reshape(-1,1)\n",
    "        vali_abs = vali_df['absences'].values.reshape(-1,1)\n",
    "        vali_df_dropped = vali_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "        vali_x = vali_df_dropped.values\n",
    "        vali_x = enc.transform(vali_x).toarray()\n",
    "        vali_x = np.hstack((vali_x, vali_age, vali_abs, vali_g1, vali_g2))\n",
    "\n",
    "        # Train the model\n",
    "        coefs = en_train(train_x, train_y, alpha=blend, lamb=alpha, max_iter=1000)\n",
    "\n",
    "        # Test on the validation set\n",
    "        vali_predict = en_predict(vali_x, coefs)\n",
    "\n",
    "        # Track performance\n",
    "        cur_mse.append(metrics.mean_squared_error(vali_y, vali_predict))\n",
    "        cur_r2.append(metrics.r2_score(vali_y, vali_predict))\n",
    "        cur_ar2.append(metrics.r2_score)\n",
    "        \n",
    "    en_results[(alpha, blend)] = [np.mean(cur_mse), np.mean(cur_r2), np.mean(cur_arw)]\n",
    "\n",
    "print(\"Used {} seconds\".format(time.time() - start))\n",
    "en_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "enc = OneHotEncoder(handle_unknown='error')\n",
    "df_array = df_dropped.values\n",
    "enc.fit(df_array)\n",
    "\n",
    "# Training set\n",
    "train_df = pd.concat([df_1, df_2, df_3, df_4, df_5])\n",
    "train_y = train_df['G3'].values\n",
    "train_age = train_df['age'].values.reshape(-1,1)\n",
    "train_g1 = train_df['G1'].values.reshape(-1,1)\n",
    "train_g2 = train_df['G2'].values.reshape(-1,1)\n",
    "train_abs = train_df['absences'].values.reshape(-1,1)\n",
    "train_df_dropped = train_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "train_x = train_df_dropped.values\n",
    "train_x = enc.transform(train_x).toarray()\n",
    "train_x = np.hstack((train_x, train_age, train_abs, train_g1, train_g2))\n",
    "\n",
    "# Test set\n",
    "test_df = pd.read_csv('./test_set.csv')\n",
    "test_y = test_df['G3'].values\n",
    "test_age = test_df['age'].values.reshape(-1,1)\n",
    "test_g1 = test_df['G1'].values.reshape(-1,1)\n",
    "test_g2 = test_df['G2'].values.reshape(-1,1)\n",
    "test_abs = test_df['absences'].values.reshape(-1,1)\n",
    "test_df_dropped = test_df.drop(['Mjob', 'Fjob', 'G1', 'G2', 'G3', 'age', 'absences'], axis=1)\n",
    "\n",
    "test_x = test_df_dropped.values\n",
    "test_x = enc.transform(test_x).toarray()\n",
    "test_x = np.hstack((test_x, test_age, test_abs, test_g1, test_g2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7910014431501344 0.862983449698729\n"
     ]
    }
   ],
   "source": [
    "(coefs, coef_track) = en_train(train_x, train_y, alpha=0.8, lamb=100, max_iter=1000)\n",
    "predict_y = en_predict(test_x, coefs)\n",
    "print(metrics.mean_squared_error(test_y, predict_y),\n",
    "      metrics.r2_score(test_y, predict_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = dict(enumerate(coef_track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_csv(\"./en_coef_change.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>services</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>M</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1   at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1   at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2    health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3     other     other   \n",
       "5     GP   M   16       U     LE3       T     4     3  services     other   \n",
       "6     GP   M   16       U     LE3       T     2     2     other     other   \n",
       "7     GP   F   17       U     GT3       A     4     4     other   teacher   \n",
       "\n",
       "   ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0  ...      4        3      4     1     1      3        6   5   6   6  \n",
       "1  ...      5        3      3     1     1      3        4   5   5   6  \n",
       "2  ...      4        3      2     2     3      3       10   7   8  10  \n",
       "3  ...      3        2      2     1     1      5        2  15  14  15  \n",
       "4  ...      4        3      2     1     2      5        4   6  10  10  \n",
       "5  ...      5        4      2     1     2      5       10  15  15  15  \n",
       "6  ...      4        4      4     1     1      3        0  12  12  11  \n",
       "7  ...      4        1      4     1     1      1        6   6   5   6  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1000, 0.1): [5.1898305502762145, 0.7586019007947982],\n",
       " (1000, 0.2): [5.105914220510753, 0.7627299959476231],\n",
       " (1000, 0.3): [5.024102872294314, 0.7667646828035627],\n",
       " (1000, 0.4): [4.953429297465515, 0.7703185616662538],\n",
       " (1000, 0.5): [4.891185673341892, 0.7736051249593453],\n",
       " (1000, 0.6): [4.833446267945211, 0.7768344963341587],\n",
       " (1000, 0.7): [4.758433210623304, 0.7808786522764268],\n",
       " (1000, 0.8): [4.661771911494286, 0.7860082579032402],\n",
       " (1000, 0.9): [4.544985472281258, 0.7921566499035165],\n",
       " (100, 0.1): [3.9528397950774647, 0.8171214292971956],\n",
       " (100, 0.2): [3.9699583282328192, 0.8165608684261318],\n",
       " (100, 0.3): [3.974569171571474, 0.8164010100154775],\n",
       " (100, 0.4): [3.966127889009273, 0.8169503125629249],\n",
       " (100, 0.5): [3.962602742983728, 0.8172942595863845],\n",
       " (100, 0.6): [3.9600923731631115, 0.8175944395849587],\n",
       " (100, 0.7): [3.9588479866542103, 0.8178387593855666],\n",
       " (100, 0.8): [3.9591899737606733, 0.8180117249493281],\n",
       " (100, 0.9): [3.961523924044492, 0.8180936127991492],\n",
       " (10, 0.1): [4.187036719536112, 0.8029062537493712],\n",
       " (10, 0.2): [4.162406798856668, 0.8042304432336899],\n",
       " (10, 0.3): [4.142419084877352, 0.8053943158269143],\n",
       " (10, 0.4): [4.127119385436208, 0.8063391192919405],\n",
       " (10, 0.5): [4.116787234898403, 0.8069973930965852],\n",
       " (10, 0.6): [4.10766136868377, 0.8075752475415591],\n",
       " (10, 0.7): [4.098832488170926, 0.8080061575103656],\n",
       " (10, 0.8): [4.0908984572049665, 0.808388965690819],\n",
       " (10, 0.9): [4.08438228921136, 0.8087430231454846],\n",
       " (1, 0.1): [4.934755363102502, 0.7613936073055424],\n",
       " (1, 0.2): [4.932293862450985, 0.7614670021362527],\n",
       " (1, 0.3): [4.930381604403896, 0.7615136775090818],\n",
       " (1, 0.4): [4.928247329835087, 0.7615771890539096],\n",
       " (1, 0.5): [4.926847779857826, 0.7616018199002312],\n",
       " (1, 0.6): [4.925833136920073, 0.761627281719931],\n",
       " (1, 0.7): [4.927515950951105, 0.7615046942682889],\n",
       " (1, 0.8): [4.931407259923052, 0.7612571354279428],\n",
       " (1, 0.9): [4.936267639574808, 0.7609605105356304],\n",
       " (0.1, 0.1): [5.2038795631117365, 0.7467211931686938],\n",
       " (0.1, 0.2): [5.204214719503346, 0.7466944155183673],\n",
       " (0.1, 0.3): [5.20454715457804, 0.7466666555443323],\n",
       " (0.1, 0.4): [5.2049597601145035, 0.7466335100745132],\n",
       " (0.1, 0.5): [5.206152207738205, 0.7465639403730149],\n",
       " (0.1, 0.6): [5.207188126442658, 0.7464998127629867],\n",
       " (0.1, 0.7): [5.20819317702532, 0.7464389926636711],\n",
       " (0.1, 0.8): [5.209798111548326, 0.7463412683779687],\n",
       " (0.1, 0.9): [5.212353482509361, 0.7461922293045344],\n",
       " (0.01, 0.1): [5.243518269998286, 0.7445728279225592],\n",
       " (0.01, 0.2): [5.243686194037559, 0.7445628031770534],\n",
       " (0.01, 0.3): [5.243858844440532, 0.7445525238078303],\n",
       " (0.01, 0.4): [5.244035330568763, 0.7445420303797565],\n",
       " (0.01, 0.5): [5.244203841067309, 0.7445317293376287],\n",
       " (0.01, 0.6): [5.244400282234123, 0.7445200911915979],\n",
       " (0.01, 0.7): [5.24464085162388, 0.7445061842725897],\n",
       " (0.01, 0.8): [5.244860967047564, 0.7444931008419498],\n",
       " (0.01, 0.9): [5.245094120774313, 0.7444795664940941],\n",
       " (0.001, 0.1): [5.248156927962426, 0.7443181471170333],\n",
       " (0.001, 0.2): [5.2481778040485585, 0.744316898056437],\n",
       " (0.001, 0.3): [5.248198801409101, 0.7443156412188656],\n",
       " (0.001, 0.4): [5.248219850450941, 0.744314381825719],\n",
       " (0.001, 0.5): [5.248239706379815, 0.7443132131286422],\n",
       " (0.001, 0.6): [5.248261384535796, 0.7443119323395584],\n",
       " (0.001, 0.7): [5.24828275520021, 0.7443106630979089],\n",
       " (0.001, 0.8): [5.248304218519787, 0.7443093884749761],\n",
       " (0.001, 0.9): [5.248325768162852, 0.7443081087733915],\n",
       " (0.0001, 0.1): [5.248645430653122, 0.7442912327059362],\n",
       " (0.0001, 0.2): [5.248647587139596, 0.7442911037942533],\n",
       " (0.0001, 0.3): [5.248649744466851, 0.7442909748312679],\n",
       " (0.0001, 0.4): [5.248651902570383, 0.7442908458224463],\n",
       " (0.0001, 0.5): [5.248654061539794, 0.7442907167602778],\n",
       " (0.0001, 0.6): [5.248656221361172, 0.7442905876461509],\n",
       " (0.0001, 0.7): [5.248658382624148, 0.7442904584613627],\n",
       " (0.0001, 0.8): [5.248660544227518, 0.7442903292409347],\n",
       " (0.0001, 0.9): [5.248662706566691, 0.74429019997721]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1, row_2, row_3, row_4, row_5 = [], [], [], [], []\n",
    "for key in en_results:\n",
    "    row_1.append(key[0])\n",
    "    row_2.append(key[1])\n",
    "    row_3.append(en_results[key][0])\n",
    "    row_4.append(en_results[key][1])\n",
    "    r2 = en_results[key][1]\n",
    "    ar2 = 1 - (1 - r2) * (79 - 1) / (79 - 89 - 1)\n",
    "    row_5.append(ar2)\n",
    "\n",
    "ddf = pd.DataFrame({'lambda': row_1, 'alpha': row_2, 'mse': row_3, 'r2': row_4, 'ar2': row_5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_csv('./en_cv_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79, 89)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
